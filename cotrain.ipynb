{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.9)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.28.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.13.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.24.6)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb matplotlib tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x79b4d59c3910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#----- imports --------\n",
    "\n",
    "import bottleneck_llm \n",
    "import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import wandb\n",
    "import os\n",
    "import tokenizers\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from itertools import chain\n",
    "from sae import TopKSparseAutoencoder\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 2e-3,\n",
    "    \"sae_learning_rate\": 5e-5,\n",
    "    \"model_embedding_layer\": 6,\n",
    "    \"eval_interval\": 500,\n",
    "    \"max_iters\": 60000, \n",
    "    \"H\": 32, # hidden dimension size\n",
    "    \"B\": 128,\n",
    "    \"T\": 256,\n",
    "    \"C\": 256,\n",
    "    \"feedforward_factor\": 3,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 12,\n",
    "    \"sae_size\": 2**14,\n",
    "    \"sae_location\": 6,\n",
    "    \"sae_topk\": 20,\n",
    "    \"sae_r2_lambda\": 2,\n",
    "    \"sae_mse_lambda\": 0,\n",
    "\n",
    "    \"tokenizer_vocab_size\": 2**13,\n",
    "    \"git_hash\": os.popen(\"git rev-parse HEAD\").read().strip()\n",
    "}\n",
    "\n",
    "# initial\n",
    "for k,v in config.items():\n",
    "    locals ()[k] = v\n",
    "\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "!wandb disabled\n",
    "\n",
    "wandb.init(\n",
    "   project = \"static-sae\",\n",
    "   config = config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stories_data = []\n",
    "# data_dir = './data'\n",
    "# for filename in os.listdir(data_dir):\n",
    "#     file_path = os.path.join(data_dir, filename)\n",
    "#     if filename.endswith('.json'):\n",
    "#         with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#             data = json.load(f)\n",
    "#             stories_data.extend(data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the tinystories tokenizer\n",
    "# tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "#     \"./tiny-stories-bpe-vocab.json\", \n",
    "#     \"./tiny-stories-bpe-merges.txt\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# def encode(text):\n",
    "#     return torch.tensor(tokenizer.encode(text).ids, dtype=torch.int64)\n",
    "# def decode(encoded_text):\n",
    "#     return tokenizer.decode(encoded_text.tolist())\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# encoded_stories = [encode(story['story']) for story in tqdm(stories_data, desc=\"Encoding stories\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the encoded stories to a file\n",
    "# torch.save(encoded_stories, 'encoded-stories.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open('tinystories-train.txt', 'r', encoding='utf-8') as f:\n",
    "#     text = f.read()\n",
    "#     print(\"length of dataset in characters: \", len(text))\n",
    "#     print(\"length of dataset in lines: \", len(text.split('\\n'))) \n",
    "#     print(text[:1000])\n",
    "    # print(\"length of dataset in characters: \", len(text[:10000]))\n",
    "    # print(\"length of dataset in tokens: \", len(encode(text[:10000])))\n",
    "    # chars_per_token = len(text[:10000]) / len(encode(text[:10000]))\n",
    "    # print(\"characters per token: \", chars_per_token) # 4.098360655737705\n",
    "chars_per_token = 4.098360655737705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = ['tinystories-train.txt']\n",
    "# tokenizer = tokenizers.ByteLevelBPETokenizer()\n",
    "\n",
    "# tokenizer.train(files=paths, vocab_size=tokenizer_vocab_size, min_frequency=2)\n",
    "\n",
    "# tokenizer.save_model('.', 'tiny-stories-bpe')\n",
    "\n",
    "\n",
    "\n",
    "# enc = tokenizer.encode(\"She sells sea shells by the sea shore!\")\n",
    "# tokenizer.decode(enc.ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    \"./tiny-stories-bpe-vocab.json\", \n",
    "    \"./tiny-stories-bpe-merges.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6099]\n",
      "hello\n",
      "vocab size:  8192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def encode(text):\n",
    "    return tokenizer.encode(text).ids\n",
    "def decode(encoded_text):\n",
    "    return tokenizer.decode(encoded_text)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def batch_encode(text, batch_size):\n",
    "    tokens = []\n",
    "    for i in tqdm(range(0, len(text), batch_size)):\n",
    "        tokens.extend(encode(text[i:i+batch_size]))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "hello_encoded = encode(\"hello\")\n",
    "print(hello_encoded)\n",
    "print(decode(hello_encoded))\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(\"vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_text = batch_encode(text, 200000)\n",
    "# # data = torch.tensor(encode(text), dtype=torch.int64)\n",
    "# data = torch.tensor(encoded_text, dtype=torch.int64, device='cuda')\n",
    "# print(data.dtype)\n",
    "# print(data.size())\n",
    "# print(data.device)\n",
    "# torch.save(data, 'tiny-stories-train.pt')\n",
    "# encoded_text = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from tiny-stories-train.pt\n",
    "data = torch.load('tiny-stories-train.pt', map_location='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468163695"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([421347325])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 427,  357,   11,  258,  405,  452,  507,  365,  600,  258, 3729,  316,\n",
       "         308,  763,   13,  312,  708,  303,  281, 2965,  265,  360,  342,  303,\n",
       "         792,  303,  281, 2120,   13,  365,  450,  265,  953,  262, 3729,  342,\n",
       "         308,  367,   11,  350,  338,  466, 5179,  258, 2227,  345,  308, 2498,\n",
       "          13,  198,  343,  475,  265,  308,  367,  264,  326,   11,  328,  775,\n",
       "          11,  335,  600,  745, 3729,   13, 1283,  346,  953,  303,  342,  525,\n",
       "         264, 5179,  656, 2498,  484,  870,  367,  505,  264,  326,   11,  328,\n",
       "         835,   11,  365,   11,  368,  478,  953,  262, 3729,  264, 1307,  633,\n",
       "        2498,  421,  198, 4611,   11,  364, 1658,  262, 3729,  264, 7866,  262,\n",
       "        2227,  345,  365,  374, 2498,   13,  415,  281,  393, 2965,  369,  454,\n",
       "         792,  364,  435, 2500,  264, 1763,  761,  576,   13, 1454,  364, 1444,\n",
       "          11,  365,  863,  308,  367,  369, 2500,  262, 3729,  264, 5132,  308,\n",
       "        2498,   13,  320,  900,  520,  411,  792,  364,  361, 1658,  264, 1370,\n",
       "         570,   13,  198,  379,  382,  380,  198,  437,  453,  258,  404,   11,\n",
       "         407,  281,  258,  405,  568,  507, 2630,  596,   13, 2630,  596,  510,\n",
       "         265,  442,  852,  264,  360,  316,  262,  738,   13, 2630,  596,  281,\n",
       "         258, 2187,  568,  792,  278,  671,  361,  594, 4815,   13, 5185, 4815,\n",
       "         567, 2630,  596,  411,  264, 1124,   13,  198,  427,  357,   11, 2630,\n",
       "         596,  281, 3472,  316,  262,  573,  593,  278,  419,  258,  413,  684,\n",
       "          13,  298,  684,  361,  795, 1510,  358,  435, 4164,   13, 2630,  596,\n",
       "         620,  717,  262, 1510, 1546,  264,  450,  265,  360,  342,  454,   13,\n",
       "        2630,  596, 1848,  893,  262], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:T+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\\n<|endoftext|>\\nOnce upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(train_data[:T+1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:T]\n",
    "y = train_data[1:T+1]\n",
    "for t in range(T):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    # print(\"when we see the text\", context, \"we predict the next character is\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, data.size(0) - T, (B,)) # 4 random locations we can sample from\n",
    "    x = torch.stack([data[i:i+T] for i in ix]) # random sequences\n",
    "    y = torch.stack([data[i+1:i+T+1] for i in ix]) # next character for each random sequence\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T): # for each of the characters in the sample\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0000,   258.0157,   516.0315,   774.0472,  1032.0630,  1290.0787,\n",
       "         1548.0945,  1806.1102,  2064.1260,  2322.1416,  2580.1575,  2838.1733,\n",
       "         3096.1890,  3354.2046,  3612.2205,  3870.2363,  4128.2520,  4386.2676,\n",
       "         4644.2832,  4902.2993,  5160.3149,  5418.3306,  5676.3467,  5934.3623,\n",
       "         6192.3779,  6450.3936,  6708.4092,  6966.4253,  7224.4409,  7482.4565,\n",
       "         7740.4727,  7998.4883,  8256.5039,  8514.5195,  8772.5352,  9030.5508,\n",
       "         9288.5664,  9546.5830,  9804.5986, 10062.6143, 10320.6299, 10578.6455,\n",
       "        10836.6611, 11094.6768, 11352.6934, 11610.7090, 11868.7246, 12126.7402,\n",
       "        12384.7559, 12642.7715, 12900.7871, 13158.8027, 13416.8184, 13674.8350,\n",
       "        13932.8506, 14190.8662, 14448.8818, 14706.8975, 14964.9131, 15222.9287,\n",
       "        15480.9453, 15738.9609, 15996.9766, 16254.9922, 16513.0078, 16771.0234,\n",
       "        17029.0391, 17287.0547, 17545.0703, 17803.0859, 18061.1016, 18319.1172,\n",
       "        18577.1348, 18835.1504, 19093.1660, 19351.1816, 19609.1973, 19867.2129,\n",
       "        20125.2285, 20383.2441, 20641.2598, 20899.2754, 21157.2910, 21415.3066,\n",
       "        21673.3223, 21931.3379, 22189.3535, 22447.3711, 22705.3867, 22963.4023,\n",
       "        23221.4180, 23479.4336, 23737.4492, 23995.4648, 24253.4805, 24511.4961,\n",
       "        24769.5117, 25027.5273, 25285.5430, 25543.5586, 25801.5742, 26059.5898,\n",
       "        26317.6055, 26575.6211, 26833.6387, 27091.6543, 27349.6699, 27607.6855,\n",
       "        27865.7012, 28123.7168, 28381.7324, 28639.7480, 28897.7637, 29155.7793,\n",
       "        29413.7949, 29671.8105, 29929.8262, 30187.8418, 30445.8574, 30703.8750,\n",
       "        30961.8906, 31219.9062, 31477.9219, 31735.9375, 31993.9531, 32251.9688,\n",
       "        32509.9844, 32768.0000], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, T*B, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    '''One Head of self-attention'''\n",
    "    def __init__(self, H):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(C, H, bias=False)\n",
    "        self.key = nn.Linear(C, H, bias=False)\n",
    "        self.value = nn.Linear(C, H, bias=False)\n",
    "        # self.output = nn.Linear(H, C, bias=False) # output matrix\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(T, T)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Query and Key matrices for the attention mechanism\n",
    "        # x: 8 tokens\n",
    "        # Q: 16 tall (arbitrary), 32 long channels\n",
    "        # K: 16 tall (arbitrary), 32 long channels\n",
    "\n",
    "        query_vectors = self.query(x)\n",
    "        key_vectors = self.key(x)\n",
    "\n",
    "\n",
    "        # Attention masking(so we can't look into the past):\n",
    "\n",
    "        tril = self.tril\n",
    "        wei = torch.zeros(T, T) \n",
    "        wei = wei.masked_fill(tril == 0, float('-inf')) # set the upper triangular to -inf\n",
    "        # xbow = wei @ x # apply the mask to the input, bag of words because simple avg.\n",
    "\n",
    "        # multiply the two to get the attention weights\n",
    "        attention_pattern = query_vectors @ key_vectors.transpose(-2, -1) # T, T\n",
    "        attention_pattern = attention_pattern / (H ** 0.5) # scale the attention pattern for numerical stability\n",
    "        attention_weights = F.softmax(attention_pattern + wei, dim=-1) # T, T (the row dimension is the query)\n",
    "\n",
    "        value_vectors = self.value(x) # the direction we should go in the embedding space for each token (ie more blue) T, H\n",
    "\n",
    "        # apply the attention weights to the value vectors\n",
    "        context = attention_weights @ value_vectors # T, H\n",
    "\n",
    "        # project back into original space from value space\n",
    "        # return self.output(context)\n",
    "        return context\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "head = Head(H)\n",
    "# head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''Multiple heads of self-attention'''\n",
    "    def __init__(self, H, C, n_heads): # H is head embedding space size, n_heads is number of heads\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(H) for _ in range(n_heads)])\n",
    "        self.combine_heads = nn.Linear(H*n_heads, C)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        x = self.combine_heads(x)  # T, C\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = MultiHeadAttention(H, C, n_heads)\n",
    "head.heads[0].forward(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    '''Feed-forward neural network'''\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(C, C * feedforward_factor),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C * feedforward_factor, C),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    '''Layer normalization'''\n",
    "    def __init__(self, C, use_affine=True):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(C)) if use_affine else None\n",
    "        self.beta = nn.Parameter(torch.zeros(C)) if use_affine else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        if self.gamma is not None and self.beta is not None:\n",
    "            return self.gamma * (x - mean) / (std + 1e-6) + self.beta\n",
    "        else:\n",
    "            return (x - mean) / (std + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    '''Transformer block'''\n",
    "    def __init__(self, H, C, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(H, C, n_heads)\n",
    "        self.ff = FeedForward(C)\n",
    "        self.norm1 = LayerNorm(C, use_affine=True)\n",
    "        self.norm2 = LayerNorm(C, use_affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoded', 'decoded', 'topk_idxs', 'topk_values', 'mse'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_sae = TopKSparseAutoencoder(C, sae_size, sae_topk)\n",
    "\n",
    "# parameters_to_optimize = list(model.parameters())\n",
    "\n",
    "# for name, param in static_sae.named_parameters():\n",
    "#     if name != 'bias':\n",
    "#         param.requires_grad=False\n",
    "#         print(f\"set {name}.requires_grad to false\")\n",
    "#     else:\n",
    "#         print(\"adding bias to list\")\n",
    "#         parameters_to_optimize.append(param)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "joint_sae.forward(torch.randn(C)).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bm_results', 'logits'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bm_results': {'encoded': tensor([[[0., -0., -0.,  ..., -0., -0., 0.],\n",
       "           [0., 0., -0.,  ..., 0., -0., -0.],\n",
       "           [-0., -0., -0.,  ..., 0., -0., 0.],\n",
       "           ...,\n",
       "           [-0., -0., 0.,  ..., 0., -0., -0.],\n",
       "           [0., 0., -0.,  ..., 0., -0., -0.],\n",
       "           [-0., 0., -0.,  ..., 0., -0., -0.]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  'decoded': tensor([[[-0.3604, -1.1380,  1.8273,  ...,  1.1712, -1.7211,  2.0981],\n",
       "           [-1.2039, -0.4544, -0.3877,  ...,  1.9344, -0.2822,  1.0722],\n",
       "           [-1.2365, -1.8186,  0.9044,  ..., -0.0207,  0.2065,  0.6823],\n",
       "           ...,\n",
       "           [-0.1802, -0.8539,  1.8924,  ...,  3.3592, -1.1636,  0.8651],\n",
       "           [-2.1220, -0.1052,  0.2190,  ...,  2.7543,  0.1774,  0.9505],\n",
       "           [-1.5532, -0.3136, -0.2871,  ...,  3.7815,  0.4556,  1.4306]]],\n",
       "         device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  'topk_idxs': tensor([[[ 4681,  1227, 12591,  ..., 14497, 12137,  7445],\n",
       "           [ 7091, 14556, 14133,  ..., 11434,  9416,  8785],\n",
       "           [ 8629, 11434, 11141,  ...,  7091, 12817, 13249],\n",
       "           ...,\n",
       "           [ 1721, 12545, 15925,  ...,   121,  6100,  9004],\n",
       "           [ 4332, 10732, 14183,  ..., 14497, 12634,  3130],\n",
       "           [ 8764, 12545, 10226,  ..., 10178, 12946,  6985]]], device='cuda:0'),\n",
       "  'topk_values': tensor([[[5.1172, 5.0407, 4.7194,  ..., 4.2197, 4.2142, 4.1927],\n",
       "           [4.8453, 4.8226, 4.7615,  ..., 4.0856, 4.0546, 4.0169],\n",
       "           [5.1614, 5.0008, 4.8093,  ..., 3.8942, 3.8937, 3.8741],\n",
       "           ...,\n",
       "           [5.0344, 4.9223, 4.9056,  ..., 3.6410, 3.6389, 3.6271],\n",
       "           [4.8166, 4.6703, 4.5486,  ..., 4.0309, 4.0228, 4.0014],\n",
       "           [6.1129, 5.4672, 4.8842,  ..., 4.2338, 4.1318, 4.1298]]],\n",
       "         device='cuda:0', grad_fn=<TopkBackward0>),\n",
       "  'mse': tensor(1.8634, device='cuda:0', grad_fn=<MeanBackward0>)},\n",
       " 'logits': tensor([[[ 0.4974, -1.1280,  0.3900,  ...,  1.4040,  0.0730, -2.0852],\n",
       "          [ 2.1589, -0.5392,  0.4568,  ..., -0.2820,  0.2968, -0.3455],\n",
       "          [ 1.5862,  0.9797,  0.5002,  ...,  0.6145,  0.3145,  0.2754],\n",
       "          ...,\n",
       "          [-0.3244, -0.8540,  0.7202,  ..., -0.8050, -0.8994,  1.9626],\n",
       "          [ 1.3897, -0.8040,  1.0301,  ..., -0.4863,  0.4869, -0.9934],\n",
       "          [ 0.0124, -1.6148,  2.2220,  ...,  0.2410,  0.8113,  1.4095]]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'loss': tensor(9.4402, device='cuda:0', grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers, bottleneck_model):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, C) \n",
    "        self.position_embedding_table = nn.Embedding(T, C)\n",
    "        self.lm_head = nn.Linear(C, vocab_size)\n",
    "        self.layers = nn.ModuleList([Block(H, C, n_heads) for _ in range(n_layers)])\n",
    "        self.bottleneck_model = bottleneck_model\n",
    "    \n",
    "    def forward(self,\n",
    "                idx,\n",
    "                targets=None,\n",
    "                bottleneck_early_stop=False\n",
    "                ):\n",
    "        bottleneck_model = self.bottleneck_model\n",
    "        B, T = idx.shape\n",
    "        token_emb = self.token_embedding_table(idx) # batch_dim, sequence_dim, embedding_dim\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T))\n",
    "        x = token_emb + pos_emb # token identities and positions contained\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if i == sae_location:\n",
    "                if bottleneck_model:\n",
    "                    bm_results = bottleneck_model(x)\n",
    "                    x = bm_results['decoded']\n",
    "                    results['bm_results'] = bm_results\n",
    "                    if bottleneck_early_stop:\n",
    "                        return results\n",
    "        \n",
    "        logits = self.lm_head(x) # batch_dim, sequence_dim, vocab_size\n",
    "\n",
    "        batch_dim, sequence_dim, embedding_dim = logits.size()\n",
    "\n",
    "        results['logits'] = logits\n",
    "\n",
    "        if targets is not None:\n",
    "            logits_loss_view = logits.view(-1, vocab_size) \n",
    "            targets_loss_view = targets.view(-1)\n",
    "            loss = F.cross_entropy(logits_loss_view, targets_loss_view)\n",
    "            results['loss'] = loss\n",
    "\n",
    "        return results\n",
    "        \n",
    "\n",
    "    def generate(self, idx, max_new_tokens, temperature=0.5):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx[:,-T:])\n",
    "            # get the predictions of the last token\n",
    "            last_token_logits = logits[:, -1, :] # all batches, last token, all probabilities\n",
    "            # apply temperature\n",
    "            last_token_logits = last_token_logits / temperature\n",
    "            # softmax to get probabilities\n",
    "            probabilities = F.softmax(last_token_logits, dim=-1)\n",
    "            # sample from the probabilities\n",
    "            next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "            # add the new token to the idx tensor\n",
    "            idx = torch.cat((idx, next_token), dim=1)\n",
    "        return idx\n",
    "    def prompt_model(self, prompt, max_new_tokens, bottleneck_model=None, temperature=0.5):\n",
    "        autoregressive_seq = encode(prompt)\n",
    "        for _ in range(max_new_tokens):\n",
    "            prediction_index = len(autoregressive_seq)-1\n",
    "\n",
    "            model_input = torch.tensor(autoregressive_seq)\n",
    "            \n",
    "            while model_input.shape[0] < T:\n",
    "                pad_token = torch.tensor(encode(\"\\n\"))\n",
    "                model_input = torch.cat((model_input, pad_token), dim=0)\n",
    "\n",
    "            model_input\n",
    "            model_input = model_input.unsqueeze(0)\n",
    "\n",
    "            model_output = model(model_input, bottleneck_model = bottleneck_model)\n",
    "            logits = model_output['logits']\n",
    "            prediction_token = logits[:, prediction_index, :] / temperature\n",
    "            probabilities = F.softmax(prediction_token, dim=-1)\n",
    "            next_token = torch.multinomial(probabilities, num_samples=1)\n",
    "            next_token = next_token.item()\n",
    "\n",
    "            autoregressive_seq.append(next_token)\n",
    "        # get the autoregressive sequence\n",
    "        return decode(autoregressive_seq)\n",
    "    def get_embedding(self, prompt, override_model_embedding_layer=None):\n",
    "        if override_model_embedding_layer is None:\n",
    "            selected_model_embedding_layer = model_embedding_layer\n",
    "        else:\n",
    "            selected_model_embedding_layer = override_model_embedding_layer\n",
    "        sequence = encode(prompt)\n",
    "        model_input = torch.tensor(sequence)\n",
    "        sequence_index = len(sequence) - 1\n",
    "        while model_input.shape[0] < T:\n",
    "            pad_token = torch.tensor(encode(\"\\n\"))\n",
    "            model_input = torch.cat((model_input, pad_token), dim=0)\n",
    "        model_input = model_input.unsqueeze(0)\n",
    "        embedding = self.forward(model_input, return_residuals=selected_model_embedding_layer)\n",
    "        # remove the batch dimension\n",
    "        embedding = embedding.squeeze(0)[sequence_index]\n",
    "        return embedding\n",
    "\n",
    "#if 'my_module' in sys.modules:\n",
    "#    del sys.modules['my_module']\n",
    "\n",
    "# 2. Reload the module\n",
    "importlib.reload(bottleneck_llm)\n",
    "\n",
    "\n",
    "model = bottleneck_llm.BottleNeckGPT(\n",
    "    B=B,\n",
    "    T=T,\n",
    "    C=C,\n",
    "    n_heads=n_heads,\n",
    "    H=H,\n",
    "    n_layers = n_layers,\n",
    "    bottleneck_model=joint_sae,\n",
    "    bottleneck_location=sae_location,\n",
    "    vocab_size=vocab_size,\n",
    "    )\n",
    "\n",
    "test_idx = torch.zeros(1, T).long()\n",
    "results = model.forward(idx=test_idx, bottleneck_early_stop=False)\n",
    "print(results.keys())\n",
    "# decode(model.generate(idx=test_idx, max_new_tokens=100)[0].tolist())\n",
    "model.forward(test_idx, targets=test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm 'joint_sae_models/bottleneck_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'haybar'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(hay, bar):\n",
    "    return hay + bar\n",
    "\n",
    "foo(\n",
    "    hay='hay',\n",
    "    bar='bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (token_embedding_table): Embedding(8192, 256)\n",
       "  (position_embedding_table): Embedding(256, 256)\n",
       "  (lm_head): Linear(in_features=256, out_features=8192, bias=True)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (query): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (key): Linear(in_features=256, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=256, out_features=32, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (combine_heads): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=768, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "    )\n",
       "  )\n",
       "  (bottleneck_model): TopKSparseAutoencoder(\n",
       "    (encode): Linear(in_features=256, out_features=16384, bias=False)\n",
       "    (decode): Linear(in_features=16384, out_features=256, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in the model:  20548864\n"
     ]
    }
   ],
   "source": [
    "# get the number of parameters in the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"number of parameters in the model: \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 10\n",
    "eval_interval = 300\n",
    "@torch.no_grad()\n",
    "def estimate_loss(is_last=False):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        real_iters = eval_iters\n",
    "        if is_last and split == 'val':  # increase last eval to mitigate noise\n",
    "            real_iters *= 10 \n",
    "        losses = torch.zeros(real_iters)\n",
    "        for k in range(real_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            model_out = model(X, Y)\n",
    "            loss = model_out['loss']\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()# / chars_per_token\n",
    "    model.train()\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params=20548864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 5291/60000 [18:45<3:14:01,  4.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_137800/3951657540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     model_out = model.forward(xb,\n\u001b[0m\u001b[1;32m     18\u001b[0m               targets=yb    )\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_137800/1623333610.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx, targets, return_residuals)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mkurtosis_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbottleneck_model\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msae_location\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottleneck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_137800/4173549379.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_137800/585342785.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/_device.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_device_constructors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# NB: This is directly called from C++ in torch/csrc/Device.cpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # \"learning_rate\": 2e-3,\n",
    "    # \"sae_learning_rate\": 5e-5,\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "logging_interval = 300\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.000001, momentum=0.9)\n",
    "# \"learning_rate\": 2e-3,\n",
    "\n",
    "import tqdm\n",
    "num_params = sum([p.numel() for p in model.parameters()])\n",
    "print(f'{num_params=}')\n",
    "\n",
    "train_logs = []\n",
    "for steps in tqdm.tqdm(range(max_iters)):\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    xb, yb = get_batch('train')\n",
    "    model_out = model.forward(xb,\n",
    "              targets=yb    )\n",
    "    loss = model_out['loss']\n",
    "    model_out['llm_loss'] = loss\n",
    "    \n",
    "    wandb.log({n: s.item() for n, s in model_out.items() if s.numel() == 1 })\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "losses = estimate_loss(is_last=True)\n",
    "# wandb.log({\"train\": losses['train'].item(), \"val\": losses['val'].item()})\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'joint_composed.pt'\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('sae_models', exist_ok=True)\n",
    "os.makedirs('joint_sae_models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main model saved to joint_sae_models/joint_composed.pt\n"
     ]
    }
   ],
   "source": [
    "model_path = f\"joint_sae_models/{model_name}\"\n",
    "\n",
    "# Save the main model\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Main model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(model.state_dict(), 'tiny-stories-model-kurtosis-regularize-0.44-loss.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "# model.load_state_dict(torch.load('models/tiny-stories-model-normal-0.44-loss.pt'))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113963/74909384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<|endoftext|>\\nOnce upon a time, there was a little boy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_113963/2683114376.py\u001b[0m in \u001b[0;36mprompt_model\u001b[0;34m(self, prompt, max_new_tokens, temperature)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkurtosis_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mprediction_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "print(model.prompt_model(\"<|endoftext|>\\nOnce upon a time, there was a little boy\", 200, 0.4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(1.8462, device='cuda:0'),\n",
       " 'val': tensor(1.8526, device='cuda:0')}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the highest value in emb1: 239\n",
      "Index of the highest value in emb2: 146\n",
      "Index of the lowest value in emb1: 203\n",
      "Index of the lowest value in emb2: 81\n",
      "emb1 excess kurtosis: -0.31801652908325195\n",
      "emb2 excess kurtosis: -0.1101229190826416\n",
      "Dot product between emb1 and emb2: 0.8099309206008911\n"
     ]
    }
   ],
   "source": [
    "story1='''Once upon a time, in a big forest, there lived a rhinoceros named Roxy. Roxy loved to climb. She climbed trees, rocks, and hills. One day, Roxy found an icy hill. She had never seen anything like it before. It was shiny and cold, and she wanted to climb it.\n",
    "Roxy tried to climb the icy hill, but it was very slippery. She tried again and again, but she kept falling down. Roxy was sad. She wanted to climb the icy hill so much. Then, she saw a little bird named Billy. Billy saw that Roxy was sad and asked, \"Why are you sad, Roxy?\"\n",
    "Roxy told Billy about the icy hill and how she couldn't climb it'''\n",
    "\n",
    "# assume BxTxC\n",
    "def excess_kurtosis(emb):\n",
    "    mean = torch.mean(emb, dim=-1, keepdim=True) # BxTx1\n",
    "    std = torch.std(emb, dim=-1, keepdim=True) # BxTx1\n",
    "\n",
    "    centralized = emb - mean #BxTxC\n",
    "    fourth_moment = torch.mean(centralized**4, dim=-1, keepdim=True) # BxTx1\n",
    "    kurtosis = torch.squeeze(fourth_moment / std**4, dim=-1) # BxT\n",
    "    return kurtosis - 3\n",
    "\n",
    "\n",
    "\n",
    "emb1 = model.get_embedding(\"Tim and Lily saw a big dog\", override_model_embedding_layer=6)\n",
    "emb2 = model.get_embedding(\"Lilly and Tim noticed a cat\", override_model_embedding_layer=6)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Plot emb1 and emb2 in the same plot\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(np.square(emb1.cpu().detach().numpy()), label='emb1', color='blue')\n",
    "# plt.plot(np.square(emb2.cpu().detach().numpy()), label='emb2', color='red')\n",
    "# plt.xlabel('Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('emb1 and emb2 Plot')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# get the index of the highest value\n",
    "# Assuming emb1 and emb2 are tensors\n",
    "highest_value_index_emb1 = torch.argmax(emb1).item()\n",
    "highest_value_index_emb2 = torch.argmax(emb2).item()\n",
    "\n",
    "lowest_value_index_emb1 = torch.argmin(emb1).item()\n",
    "lowest_value_index_emb2 = torch.argmin(emb2).item()\n",
    "\n",
    "print(f\"Index of the highest value in emb1: {highest_value_index_emb1}\")\n",
    "print(f\"Index of the highest value in emb2: {highest_value_index_emb2}\")\n",
    "print(f\"Index of the lowest value in emb1: {lowest_value_index_emb1}\")\n",
    "print(f\"Index of the lowest value in emb2: {lowest_value_index_emb2}\")\n",
    "\n",
    "print(f\"emb1 excess kurtosis: {excess_kurtosis(emb1)}\")\n",
    "print(f\"emb2 excess kurtosis: {excess_kurtosis(emb2)}\")\n",
    "\n",
    "# dot product between emb1 and emb2\n",
    "emb1_l2 = F.normalize(emb1, p=2, dim=-1)\n",
    "emb2_l2 = F.normalize(emb2, p=2, dim=-1)\n",
    "print(f\"Dot product between emb1 and emb2: {torch.dot(emb1_l2, emb2_l2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emb1 excess kurtosis: 157.1050262451172\n",
    "emb2 excess kurtosis: 156.85986328125\n",
    "when we load the model trained from this notebook, it has excess kurtosis of 157.1050262451172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3952, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('val')\n",
    "emb = model.forward(xb, return_residuals=model_embedding_layer)\n",
    "\n",
    "# emb.shape\n",
    "kurtosis_values = excess_kurtosis(emb).view(-1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert kurtosis values to CPU and numpy for plotting\n",
    "kurtosis_np = kurtosis_values.cpu().detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(kurtosis_np, bins=50, edgecolor='black')\n",
    "plt.xlabel('Excess Kurtosis')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Excess Kurtosis Values kurtosis regularized model at loss 0.44 ')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(kurtosis_values.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
